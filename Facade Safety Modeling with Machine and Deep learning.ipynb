{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Number of Stories median: 8\n",
      "Building Area median: 100992\n",
      "Year Built median: 1948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "print (\"Reading data...\")\n",
    "path = \"C:\\\\Users\\\\tahalam\\\\Documents\\\\FACADE SAFETY PROJECTS\\\\datasets\\\\\"\n",
    "#Import facade dataset\n",
    "f  = pd.read_csv(path+\"Final Facade dataset.csv\")\n",
    "\n",
    "f[\"Bin\"] = f[\"Bin\"].astype(str)\n",
    "f[\"Address\"] = f[\"Address\"] + \" \" + f[\"Borough\"]\n",
    "f[\"CITY OWNED\"] = f[\"CITY OWNED\"].fillna(0)\n",
    "f[\"CITY OWNED\"] = f[\"CITY OWNED\"].astype(int)\n",
    "\n",
    "# INSERT OWNER PROFILE NAME INTO FACADE DATASET\n",
    "op =  pd.read_csv(path + \"BIN_OwnerProfile_Facades.csv\", low_memory=False)\n",
    "op[\"Bin\"] = op[\"Bin\"].astype(str)\n",
    "dfDic = op.set_index('Bin')['OwnerProfile'].to_dict()\n",
    "#use mapping function\n",
    "f[\"OwnerProfile\"] = f[\"Bin\"].map(dfDic)\n",
    "\n",
    "\n",
    "#remove variables not needed for the analysis\n",
    "f = f.drop('BBL', 1)\n",
    "#f = f.drop('Bin', 1)\n",
    "f = f.drop('Exterior Wall Types', 1)\n",
    "#f = f.drop('Address', 1)\n",
    "f = f.drop('Building Front', 1)\n",
    "f = f.drop('Lot Front', 1)\n",
    "f = f.drop('Owner Name', 1)\n",
    "#f = f.drop('QEWI NAME', 1)\n",
    "f = f.drop('COMP', 1)\n",
    "f = f.drop('ECB', 1)\n",
    "f = f.drop('DOB', 1)\n",
    "f = f.drop('DAN', 1)\n",
    "f = f.drop('Historical', 1)\n",
    "f = f.drop('Borough', 1)\n",
    "f = f.drop('Building Class', 1)\n",
    "f = f.drop('Proximity Code', 1)\n",
    "\n",
    "\n",
    "f['QEWI NAME'] = f['QEWI NAME'].str.replace(' ', '_')\n",
    "\n",
    "\n",
    "### CLEAN NUMBER OF STORIES, YEAR, BUILDING AREA\n",
    "f['Number Of Stories']=f['Number Of Stories'].str.extract('(^[0-9|-]*)')\n",
    "\n",
    "f[\"Number Of Stories\"] = f[\"Number Of Stories\"].fillna(0)\n",
    "median =  str(int(f[\"Number Of Stories\"].median() ) )\n",
    "print (\"Number of Stories median:\",  median)\n",
    "f[\"Number Of Stories\"] = f[\"Number Of Stories\"].astype(str)\n",
    "\n",
    "for i in range(0, len(f)):\n",
    "    if f[\"Number Of Stories\"][i] == \"0\":\n",
    "        #print f[\"Number Of Stories\"][i]\n",
    "        f[\"Number Of Stories\"][i] = median\n",
    "        #print f[\"Number Of Stories\"][i]\n",
    "\n",
    "f[\"Number Of Stories\"] = f[\"Number Of Stories\"].astype(int)\n",
    "\n",
    "f[\"Building Area\"] = f[\"Building Area\"].astype(str).replace('\\.0', '', regex=True)\n",
    "f[\"Building Area\"] = f[\"Building Area\"].astype(str)\n",
    "f[\"Building Area\"] = f[\"Building Area\"].str.replace(' ', 'nan')\n",
    "f[\"Building Area\"] = f[\"Building Area\"].map(str.strip)\n",
    "f[\"Building Area\"] = f[\"Building Area\"].str.replace('nan', '0')\n",
    "f[\"Building Area\"] = f[\"Building Area\"].astype(int)\n",
    "median =  str(int(f[\"Building Area\"].median() ) )\n",
    "print (\"Building Area median:\",  median)\n",
    "f[\"Building Area\"] = f[\"Building Area\"].astype(str)\n",
    "\n",
    "for i in range(0, len(f)):\n",
    "    if f[\"Building Area\"][i] == \"0\":\n",
    "        #print f[\"Number Of Stories\"][i]\n",
    "        f[\"Building Area\"][i] = median\n",
    "        #print f[\"Number Of Stories\"][i]\n",
    "f[\"Building Area\"] = f[\"Building Area\"].astype(int)        \n",
    "\n",
    "f[\"Year Built\"] = f[\"Year Built\"].astype(str)\n",
    "f[\"Year Built\"] = f[\"Year Built\"].str.replace('nan', '0')\n",
    "f[\"Year Built\"] = f[\"Year Built\"].str.replace(' ', 'nan')\n",
    "f[\"Year Built\"] = f[\"Year Built\"].str.replace('nan', '0')\n",
    "f[\"Year Built\"] = f[\"Year Built\"].astype(int)\n",
    "median =  str(int(f[\"Year Built\"].median() ) )\n",
    "print (\"Year Built median:\",  median)\n",
    "f[\"Year Built\"] = f[\"Year Built\"].astype(str)\n",
    "count = 0\n",
    "for i in range(0, len(f)):\n",
    "    if f[\"Year Built\"][i] == \"0\":\n",
    "        #print f[\"Number Of Stories\"][i]\n",
    "        f[\"Year Built\"][i] = median\n",
    "        count+=1\n",
    "        #print f[\"Number Of Stories\"][i]        \n",
    "\n",
    "f[\"Year Built\"] = f[\"Year Built\"].astype(int)     \n",
    "#print \"count\", count     \n",
    "#f[\"Year Built\"] = f[\"Year Built\"].astype(int)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Categories\n",
    "creating new categories based on stories, building area and year built\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bin</th>\n",
       "      <th>CB Number</th>\n",
       "      <th>Address</th>\n",
       "      <th>QEWI NAME</th>\n",
       "      <th>CITY OWNED</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Building Type</th>\n",
       "      <th>Active Shed</th>\n",
       "      <th>OwnerProfile</th>\n",
       "      <th>Year Category</th>\n",
       "      <th>Stories Category</th>\n",
       "      <th>Build Area Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1 WATER STREET MANHATTAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Residential</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968_2007</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000006</td>\n",
       "      <td>101.0</td>\n",
       "      <td>125 BROAD STREET MANHATTAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Residential</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968_2007</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000007</td>\n",
       "      <td>101.0</td>\n",
       "      <td>115 BROAD STREET MANHATTAN</td>\n",
       "      <td>PAUL_VALERIO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968_2007</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000016</td>\n",
       "      <td>101.0</td>\n",
       "      <td>102 BROAD STREET MANHATTAN</td>\n",
       "      <td>ROY_SOKOLOSKI</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Government</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1938_1967</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Medium_Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000018</td>\n",
       "      <td>101.0</td>\n",
       "      <td>34 WHITEHALL STREET MANHATTAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968_2007</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Medium_High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bin  CB Number                        Address      QEWI NAME  \\\n",
       "0  1000005      101.0       1 WATER STREET MANHATTAN            NaN   \n",
       "1  1000006      101.0     125 BROAD STREET MANHATTAN            NaN   \n",
       "2  1000007      101.0     115 BROAD STREET MANHATTAN   PAUL_VALERIO   \n",
       "3  1000016      101.0     102 BROAD STREET MANHATTAN  ROY_SOKOLOSKI   \n",
       "4  1000018      101.0  34 WHITEHALL STREET MANHATTAN            NaN   \n",
       "\n",
       "   CITY OWNED  Outcome Building Type  Active Shed OwnerProfile Year Category  \\\n",
       "0           0        0   Residential            0          NaN     1968_2007   \n",
       "1           0        1   Residential            1          NaN     1968_2007   \n",
       "2           0        0    Commercial            0          NaN     1968_2007   \n",
       "3           0        1    Government            0          NaN     1938_1967   \n",
       "4           0        0    Commercial            0          NaN     1968_2007   \n",
       "\n",
       "  Stories Category Build Area Category  \n",
       "0        High Rise               Large  \n",
       "1        High Rise               Large  \n",
       "2        High Rise               Large  \n",
       "3        High Rise          Medium_Low  \n",
       "4        High Rise         Medium_High  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"Year Category\"] = \"\"  \n",
    "f[\"Stories Category\"] = \"\"\n",
    "f[\"Build Area Category\"] = \"\"\n",
    "\n",
    "for i in range(0, len(f)):\n",
    "    if f[\"Year Built\"][i] < 1900:\n",
    "        f[\"Year Category\"][i] = \"pre_1900\"\n",
    "        \n",
    "    if (f[\"Year Built\"][i] >= 1900 and f[\"Year Built\"][i] < 1916):\n",
    "        f[\"Year Category\"][i] = \"1900_1915\"\n",
    "        \n",
    "    if (f[\"Year Built\"][i] >= 1916 and f[\"Year Built\"][i] < 1938):\n",
    "        f[\"Year Category\"][i] = \"1916_1937\"\n",
    "        \n",
    "    if (f[\"Year Built\"][i] >= 1938 and f[\"Year Built\"][i] < 1968):\n",
    "        f[\"Year Category\"][i] = \"1938_1967\"\n",
    "        \n",
    "    if (f[\"Year Built\"][i] >= 1968 and f[\"Year Built\"][i] < 2008):\n",
    "        f[\"Year Category\"][i] = \"1968_2007\"\n",
    "        \n",
    "    if (f[\"Year Built\"][i] >= 2008 and f[\"Year Built\"][i] < 2019):\n",
    "        f[\"Year Category\"][i] = \"2008_2019\"\n",
    "        \n",
    "\n",
    "        \n",
    "    if f[\"Number Of Stories\"][i] < 10:\n",
    "        f[\"Stories Category\"][i] = \"Low Rise\"\n",
    "        \n",
    "    if f[\"Number Of Stories\"][i] >= 10:\n",
    "        f[\"Stories Category\"][i] = \"High Rise\"\n",
    "        \n",
    "     \n",
    "    if f[\"Building Area\"][i] <= 50000 :\n",
    "        f[\"Build Area Category\"][i] = \"Low_Small\"\n",
    "    if (f[\"Building Area\"][i] > 50000 and f[\"Building Area\"][i] <= 100000):\n",
    "        f[\"Build Area Category\"][i] = \"High_Small\"\n",
    "    if (f[\"Building Area\"][i] > 100000 and f[\"Building Area\"][i] <= 250000):\n",
    "        f[\"Build Area Category\"][i] = \"Medium_Low\"\n",
    "    if (f[\"Building Area\"][i] > 250000 and f[\"Building Area\"][i] <= 1000000):\n",
    "        f[\"Build Area Category\"][i] = \"Medium_High\" \n",
    "    if (f[\"Building Area\"][i] > 1000000 ):\n",
    "        f[\"Build Area Category\"][i] = \"Large\"   \n",
    "        \n",
    "        \n",
    "f = f.drop('Year Built', 1)\n",
    "f = f.drop('Number Of Stories', 1)\n",
    "f = f.drop('Building Area', 1)\n",
    "f= f.drop('Unnamed: 0', 1)\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummies for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ownership dummies...\n",
      "Creating Architect dummmies...\n",
      "Creating community board dummies...\n",
      "number of comm boards 62\n",
      "Creating building type dummies ...\n",
      "number of build types 7\n",
      "Creating year dummies ...\n",
      "Creating stories category ...\n",
      "Creating building area category ...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "## Create Dummies for modeling\n",
    "#Owners\n",
    "print (\"Creating ownership dummies...\")\n",
    "own_dummies = pd.get_dummies(f.OwnerProfile)\n",
    "\n",
    "#own_dummies = own_dummies.drop('', 1)\n",
    "#own_dummies = own_dummies.drop('#_#', 1)\n",
    "#own_dummies = own_dummies.drop('000_000', 1)\n",
    "ownCols = own_dummies.columns\n",
    "\n",
    "#drop columns with owner frequency less than or equal to 10\n",
    "for i in range(0, len(ownCols)):\n",
    "#for i in range(0, 100):\n",
    "    sumOwn = own_dummies[ownCols[i]].sum()\n",
    "    if sumOwn <= 10:\n",
    "        own_dummies = own_dummies.drop(ownCols[i], 1)\n",
    "        \n",
    "f = pd.concat([f, own_dummies], axis=1)\n",
    "f = f.drop('OwnerProfile', 1)\n",
    "\n",
    "\n",
    "print (\"Creating Architect dummmies...\")\n",
    "\n",
    "arch_dummies = pd.get_dummies(f[\"QEWI NAME\"], prefix='QEWI')\n",
    "\n",
    "archCols = arch_dummies.columns\n",
    "\n",
    "#drop columns with architect frequency less than 10\n",
    "for i in range(0, len(archCols)):\n",
    "    sumArch = arch_dummies[archCols[i]].sum()\n",
    "    if sumArch < 10:\n",
    "        arch_dummies = arch_dummies.drop(archCols[i], 1)\n",
    "\n",
    "f = pd.concat([f, arch_dummies], axis=1)\n",
    "f = f.drop('QEWI NAME', 1)\n",
    "\n",
    "\n",
    "print (\"Creating community board dummies...\")\n",
    "\n",
    "f[\"CB Number\"] = f['CB Number'].astype(str)\n",
    "f[\"CB Number\"] = f['CB Number'].str.split(\".\").str[0]\n",
    "\n",
    "print (\"number of comm boards\", len(set(f[\"CB Number\"].tolist())))\n",
    "\n",
    "cbdummies = pd.get_dummies(f[\"CB Number\"], prefix='CB')\n",
    "cbdummies = cbdummies.drop(\"CB_nan\", 1)\n",
    "\n",
    "f = pd.concat([f, cbdummies], axis=1)\n",
    "f = f.drop('CB Number', 1)\n",
    "\n",
    "print (\"Creating building type dummies ...\")\n",
    "print (\"number of build types\", len(set(f[\"Building Type\"].tolist())))\n",
    "\n",
    "btdummies = pd.get_dummies(f[\"Building Type\"], prefix='BT')\n",
    "#btdummies = btdummies.drop(\"BT_nan\", 1)\n",
    "\n",
    "f = pd.concat([f, btdummies], axis=1)\n",
    "f = f.drop('Building Type', 1)\n",
    "\n",
    "print (\"Creating year dummies ...\")\n",
    "yrdummies = pd.get_dummies(f[\"Year Category\"])\n",
    "f = pd.concat([f, yrdummies], axis=1)\n",
    "f = f.drop('Year Category', 1)\n",
    "\n",
    "print (\"Creating stories category ...\")\n",
    "strdummies = pd.get_dummies(f[\"Stories Category\"])\n",
    "f = pd.concat([f, strdummies], axis=1)\n",
    "f = f.drop('Stories Category', 1)\n",
    "\n",
    "\n",
    "print (\"Creating building area category ...\")\n",
    "strdummies = pd.get_dummies(f[\"Build Area Category\"], prefix='BA')\n",
    "f = pd.concat([f, strdummies], axis=1)\n",
    "f = f.drop('Build Area Category', 1)\n",
    "\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Balance Class\n",
    "Creates a dataset where unsafe and safe buildings represent equal parts of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of majority class 11941\n",
      "Size of minority class 2717\n",
      "Size of minority class upsampled 11941\n",
      "Display new class counts\n",
      "Randomly sort f2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = f[f.Outcome==0]\n",
    "df_minority = f[f.Outcome==1]\n",
    "\n",
    "print (\"Size of majority class\", len(df_majority))\n",
    "print (\"Size of minority class\", len(df_minority))\n",
    "\n",
    "lenMajority = len(df_majority)\n",
    "\n",
    "\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=lenMajority, # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "print (\"Size of minority class upsampled\", len(df_minority_upsampled))\n",
    "\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "f2 = pd.concat([df_majority, df_minority_upsampled])\n",
    "f2 = f2.reset_index(drop=True)\n",
    " \n",
    "print (\"Display new class counts\")\n",
    "f2.Outcome.value_counts()\n",
    "\n",
    "print (\"Randomly sort f2\")\n",
    "f2[\"Index\"] = f2.index\n",
    "f2 = f2.sample(frac=1)\n",
    "f2 = f2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: Dummy majority score: 0.5\n",
      "\n",
      "IMPLEMENT SEVERAL MODELS\n",
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest changing params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTED DECISION TREES\n",
      "Gradient boosting default parameters\n",
      "\n",
      "Adjusting gradient boosted learning rate and depth\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "Default parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Varying regularization c parameter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAIVE BAYES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "pd.set_option('chained_assignment', None)\n",
    "    \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "#create data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    \n",
    "model_selection = []\n",
    "    \n",
    "def AccuracyAndAUC(model, clf, X_test, y_test, a, b):\n",
    "    a = \"(\" + a + \",\"\n",
    "    b = b + \")\"\n",
    "    accuracy_param = a + b\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "   \n",
    "        \n",
    "    pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    roc=roc_auc_score(y_test, pred_prob)\n",
    "    #print ('AUC:', round(roc, 2))\n",
    "\n",
    "        \n",
    "    #clf_predicted = clf.predict(X_test)\n",
    "    #confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "    #print('Classifier Confusion Matrix\\n', confusion)\n",
    "    #print()\n",
    "        \n",
    "    model_selection.append([model,accuracy_param, clf.score(X_train, y_train), accuracy_score(y_test, clf_predicted),\n",
    "                               precision_score(y_test, clf_predicted),recall_score(y_test, clf_predicted), \n",
    "                                f1_score(y_test, clf_predicted), roc])\n",
    "        \n",
    "        \n",
    "        \n",
    "def AccuracySVM(clf, X_test, y_test, a, b):\n",
    "    a = \"(\" + a + \",\"\n",
    "    b = b + \")\"\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "    print ()\n",
    "    print (\"Accuracy on these parameters\", a, b)\n",
    "    print('Accuracy on test set: {:.2f}'.format(accuracy_score(y_test, clf_predicted)))\n",
    "    print('Precision: {:.2f}'.format(precision_score(y_test, clf_predicted)))\n",
    "    print('Recall: {:.2f}'.format(recall_score(y_test, clf_predicted)))\n",
    "    print('F1: {:.2f}'.format(f1_score(y_test, clf_predicted)))\n",
    "        \n",
    "    #pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    #roc=roc_auc_score(y_test, pred_prob)\n",
    "    #print ('AUC:', round(roc, 2))\n",
    "        \n",
    "    y_score_gb = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_gb)\n",
    "    roc_auc_gb = auc(fpr_lr, tpr_lr)\n",
    "    print (\"AUC:\", round(roc_auc_gb, 2))\n",
    "\n",
    "\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "    confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "    print('Classifier Confusion Matrix\\n', confusion)\n",
    "        \n",
    "        \n",
    "def PlotROC(clf, X_test, y_test):\n",
    "    y_score_gb = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_gb)\n",
    "    roc_auc = auc(fpr_lr, tpr_lr)\n",
    "    #PLOT\n",
    "    plt.figure()\n",
    "    plt.xlim([-0.01, 1.00])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.plot(fpr_lr, tpr_lr, lw=3, label='ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "    plt.legend(loc='lower right', fontsize=13)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "    plt.axes().set_aspect('equal')\n",
    "    plt.show()\n",
    "        \n",
    "    return plt.show()\n",
    "    \n",
    "  \n",
    "#MODEL\n",
    "#make a copy of the upsampled dataset\n",
    "f3 = f2.copy()\n",
    "y = f3[\"Outcome\"]\n",
    "X = f3.drop('Outcome', 1)\n",
    "X = X.drop('Bin', 1)\n",
    "X = X.drop('Address', 1)\n",
    "X = X.drop('Index', 1)\n",
    "X = X.drop('CITY OWNED',1)\n",
    "X = X.drop('Active Shed',1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "#test baseline using dummy classifier\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "    \n",
    "print (\"Baseline Accuracy: Dummy majority score:\", round(dummy_majority.score(X_test, y_test), 2) )\n",
    "print ()\n",
    "\n",
    "print (\"IMPLEMENT SEVERAL MODELS\")\n",
    "\n",
    "\n",
    "#RANDOM FORESTS\n",
    "print (\"Random Forest\")\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Random Forest\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "print (\"Random Forest changing params\")\n",
    "max_depth_list = [10,12,14, 16, 18]\n",
    "\n",
    "maximumFeat = int(math.sqrt(len(X_train.columns) ) )\n",
    "    \n",
    "#max_features = sqrt(number of features)\n",
    "for max_d in max_depth_list:\n",
    "    #print \"max features\", maximumFeat\n",
    "    clf = RandomForestClassifier(max_features = maximumFeat, max_depth = max_d, random_state = 0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    a = \"max features:\" + str(maximumFeat)\n",
    "    b = \"max depth:\" + str(max_d)\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    \n",
    "#GRADIENT BOOSTED DECISION TREES\n",
    "print (\"GRADIENT BOOSTED DECISION TREES\")\n",
    "print (\"Gradient boosting default parameters\")\n",
    "clf = GradientBoostingClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Gradient Boosted Dec Trees\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "#PlotROC(clf, X_test, y_test)\n",
    "    \n",
    "print ()\n",
    "print (\"Adjusting gradient boosted learning rate and depth\")\n",
    "learn_rate = [0.01, 0.1, 1]\n",
    "max_depth = [2,4,6]\n",
    "    \n",
    "for learn in learn_rate:\n",
    "    for depth in max_depth:\n",
    "        clf = GradientBoostingClassifier(learning_rate = learn, max_depth = depth, random_state = 0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        a = \"learning rate:\" + str(learn)\n",
    "        b = \"maximum depth:\" + str(depth)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "    \n",
    "#LOGISTIC REGRESSION\n",
    "print ()\n",
    "print (\"LOGISTIC REGRESSION\")\n",
    "print (\"Default parameters\")\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Logistic Regression\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "print ()\n",
    "print (\"Varying regularization c parameter\")\n",
    "this_C_list = [0.1, 1, 100]\n",
    "b = \"none\"\n",
    "for this_C in this_C_list:\n",
    "    a = \"C reg param:\" + str(this_C)\n",
    "    clf = LogisticRegression(C=this_C).fit(X_train, y_train)\n",
    "    AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "#NAIVE BAYES\n",
    "print ()\n",
    "print (\"NAIVE BAYES\")\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "model = \"Naive Bayes\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "\n",
    "\"\"\"\n",
    "#SVM\n",
    "print (\"SUPPORT VECTOR MACHINES\")\n",
    "#print (\"With default RBF Kernal and MinMax Scaling\")\n",
    "model = \"SVM\"\n",
    "a = \"MinMax Scalaing\"\n",
    "b = \"Grid Search\"\n",
    "accuracy_param = \"(\" + a + \",\" + b + \")\"\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#clf = SVC(random_state = 0)\n",
    "#clf.fit(X_train_scaled, y_train)\n",
    "#AccuracySVM(clf, X_test_scaled, y_test, a, b)\n",
    "    \n",
    "print (\"SVM with RBF kernal and grid search optimizing for AUC\")\n",
    "    \n",
    "clf = SVC(kernel='rbf')\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]}\n",
    "    \n",
    "grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test_scaled) \n",
    "\n",
    "print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "\"\"\"    \n",
    "df2 = pd.DataFrame(model_selection, columns=('Model','Parameters', 'Training Score', 'Test Score', 'Precision', 'Recall', 'F1', 'AUC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.935291</td>\n",
       "      <td>0.848434</td>\n",
       "      <td>0.802397</td>\n",
       "      <td>0.922999</td>\n",
       "      <td>0.858483</td>\n",
       "      <td>0.929286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:19,max depth:10)</td>\n",
       "      <td>0.658869</td>\n",
       "      <td>0.641099</td>\n",
       "      <td>0.709320</td>\n",
       "      <td>0.473436</td>\n",
       "      <td>0.567856</td>\n",
       "      <td>0.710865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:19,max depth:12)</td>\n",
       "      <td>0.675618</td>\n",
       "      <td>0.651817</td>\n",
       "      <td>0.721206</td>\n",
       "      <td>0.490585</td>\n",
       "      <td>0.583950</td>\n",
       "      <td>0.722351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:19,max depth:14)</td>\n",
       "      <td>0.704651</td>\n",
       "      <td>0.678278</td>\n",
       "      <td>0.726842</td>\n",
       "      <td>0.567249</td>\n",
       "      <td>0.637205</td>\n",
       "      <td>0.754273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:19,max depth:16)</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>0.692514</td>\n",
       "      <td>0.764898</td>\n",
       "      <td>0.552455</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>0.771648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>(max features:19,max depth:18)</td>\n",
       "      <td>0.740550</td>\n",
       "      <td>0.702562</td>\n",
       "      <td>0.767172</td>\n",
       "      <td>0.578346</td>\n",
       "      <td>0.659509</td>\n",
       "      <td>0.786053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.664285</td>\n",
       "      <td>0.651482</td>\n",
       "      <td>0.707578</td>\n",
       "      <td>0.511769</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>0.726118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:2)</td>\n",
       "      <td>0.595277</td>\n",
       "      <td>0.588679</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.348352</td>\n",
       "      <td>0.457597</td>\n",
       "      <td>0.630562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:4)</td>\n",
       "      <td>0.636760</td>\n",
       "      <td>0.625858</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.432078</td>\n",
       "      <td>0.534971</td>\n",
       "      <td>0.673747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.01,maximum depth:6)</td>\n",
       "      <td>0.644632</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>0.697402</td>\n",
       "      <td>0.460323</td>\n",
       "      <td>0.554588</td>\n",
       "      <td>0.695737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:2)</td>\n",
       "      <td>0.642119</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>0.694041</td>\n",
       "      <td>0.466039</td>\n",
       "      <td>0.557634</td>\n",
       "      <td>0.699761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:4)</td>\n",
       "      <td>0.693931</td>\n",
       "      <td>0.674091</td>\n",
       "      <td>0.724063</td>\n",
       "      <td>0.558507</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>0.751917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:0.1,maximum depth:6)</td>\n",
       "      <td>0.737368</td>\n",
       "      <td>0.697538</td>\n",
       "      <td>0.737785</td>\n",
       "      <td>0.609280</td>\n",
       "      <td>0.667403</td>\n",
       "      <td>0.780031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:2)</td>\n",
       "      <td>0.698174</td>\n",
       "      <td>0.674929</td>\n",
       "      <td>0.684398</td>\n",
       "      <td>0.644586</td>\n",
       "      <td>0.663896</td>\n",
       "      <td>0.744119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:4)</td>\n",
       "      <td>0.779353</td>\n",
       "      <td>0.736895</td>\n",
       "      <td>0.742314</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>0.732322</td>\n",
       "      <td>0.821201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient Boosted Dec Trees</td>\n",
       "      <td>(learning rate:1,maximum depth:6)</td>\n",
       "      <td>0.859807</td>\n",
       "      <td>0.795847</td>\n",
       "      <td>0.785924</td>\n",
       "      <td>0.811029</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>0.873484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.679415</td>\n",
       "      <td>0.661698</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.653635</td>\n",
       "      <td>0.727615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:0.1,none)</td>\n",
       "      <td>0.676009</td>\n",
       "      <td>0.660526</td>\n",
       "      <td>0.671248</td>\n",
       "      <td>0.624075</td>\n",
       "      <td>0.646803</td>\n",
       "      <td>0.717759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:1,none)</td>\n",
       "      <td>0.679415</td>\n",
       "      <td>0.661698</td>\n",
       "      <td>0.666900</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.653635</td>\n",
       "      <td>0.727615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>(C reg param:100,none)</td>\n",
       "      <td>0.682151</td>\n",
       "      <td>0.660526</td>\n",
       "      <td>0.662883</td>\n",
       "      <td>0.647949</td>\n",
       "      <td>0.655331</td>\n",
       "      <td>0.726628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.558930</td>\n",
       "      <td>0.550494</td>\n",
       "      <td>0.526822</td>\n",
       "      <td>0.957633</td>\n",
       "      <td>0.679714</td>\n",
       "      <td>0.555159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model                            Parameters  \\\n",
       "0                Random Forest                     (default,default)   \n",
       "1                Random Forest        (max features:19,max depth:10)   \n",
       "2                Random Forest        (max features:19,max depth:12)   \n",
       "3                Random Forest        (max features:19,max depth:14)   \n",
       "4                Random Forest        (max features:19,max depth:16)   \n",
       "5                Random Forest        (max features:19,max depth:18)   \n",
       "6   Gradient Boosted Dec Trees                     (default,default)   \n",
       "7   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:2)   \n",
       "8   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:4)   \n",
       "9   Gradient Boosted Dec Trees  (learning rate:0.01,maximum depth:6)   \n",
       "10  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:2)   \n",
       "11  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:4)   \n",
       "12  Gradient Boosted Dec Trees   (learning rate:0.1,maximum depth:6)   \n",
       "13  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:2)   \n",
       "14  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:4)   \n",
       "15  Gradient Boosted Dec Trees     (learning rate:1,maximum depth:6)   \n",
       "16         Logistic Regression                     (default,default)   \n",
       "17         Logistic Regression                (C reg param:0.1,none)   \n",
       "18         Logistic Regression                  (C reg param:1,none)   \n",
       "19         Logistic Regression                (C reg param:100,none)   \n",
       "20                 Naive Bayes                     (default,default)   \n",
       "\n",
       "    Training Score  Test Score  Precision    Recall        F1       AUC  \n",
       "0         0.935291    0.848434   0.802397  0.922999  0.858483  0.929286  \n",
       "1         0.658869    0.641099   0.709320  0.473436  0.567856  0.710865  \n",
       "2         0.675618    0.651817   0.721206  0.490585  0.583950  0.722351  \n",
       "3         0.704651    0.678278   0.726842  0.567249  0.637205  0.754273  \n",
       "4         0.726816    0.692514   0.764898  0.552455  0.641546  0.771648  \n",
       "5         0.740550    0.702562   0.767172  0.578346  0.659509  0.786053  \n",
       "6         0.664285    0.651482   0.707578  0.511769  0.593951  0.726118  \n",
       "7         0.595277    0.588679   0.666667  0.348352  0.457597  0.630562  \n",
       "8         0.636760    0.625858   0.702186  0.432078  0.534971  0.673747  \n",
       "9         0.644632    0.631720   0.697402  0.460323  0.554588  0.695737  \n",
       "10        0.642119    0.631720   0.694041  0.466039  0.557634  0.699761  \n",
       "11        0.693931    0.674091   0.724063  0.558507  0.630600  0.751917  \n",
       "12        0.737368    0.697538   0.737785  0.609280  0.667403  0.780031  \n",
       "13        0.698174    0.674929   0.684398  0.644586  0.663896  0.744119  \n",
       "14        0.779353    0.736895   0.742314  0.722596  0.732322  0.821201  \n",
       "15        0.859807    0.795847   0.785924  0.811029  0.798279  0.873484  \n",
       "16        0.679415    0.661698   0.666900  0.640888  0.653635  0.727615  \n",
       "17        0.676009    0.660526   0.671248  0.624075  0.646803  0.717759  \n",
       "18        0.679415    0.661698   0.666900  0.640888  0.653635  0.727615  \n",
       "19        0.682151    0.660526   0.662883  0.647949  0.655331  0.726628  \n",
       "20        0.558930    0.550494   0.526822  0.957633  0.679714  0.555159  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL SELECTION NEURAL NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network changing params...\n",
      "Going through params...\n",
      "Going through params...\n",
      "Going through params...\n",
      "Going through params...\n",
      "Going through params...\n",
      "Going through params...\n",
      "Going through params...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Default X AND y\n",
    "model_selection = []\n",
    "    \n",
    "def AccuracyAndAUC(model, clf, X_test, y_test, a, b):\n",
    "    a = \"(\" + a + \",\"\n",
    "    b = b + \")\"\n",
    "    accuracy_param = a + b\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "   \n",
    "        \n",
    "    pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    roc=roc_auc_score(y_test, pred_prob)\n",
    "    #print ('AUC:', round(roc, 2))\n",
    "\n",
    "        \n",
    "    #clf_predicted = clf.predict(X_test)\n",
    "    #confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "    #print('Classifier Confusion Matrix\\n', confusion)\n",
    "    #print()\n",
    "        \n",
    "    model_selection.append([model,accuracy_param, clf.score(X_train, y_train), accuracy_score(y_test, clf_predicted),\n",
    "                               precision_score(y_test, clf_predicted),recall_score(y_test, clf_predicted),\n",
    "                            f1_score(y_test, clf_predicted), roc])\n",
    "\n",
    "\n",
    "f4 = f2.copy()\n",
    "f4[\"CITY OWNED\"] = f4[\"CITY OWNED\"].fillna(0)\n",
    "f4[\"CITY OWNED\"] = f4[\"CITY OWNED\"].astype(int)\n",
    "y = f4[\"Outcome\"]\n",
    "X = f4.drop('Outcome', 1)\n",
    "X = X.drop('Bin', 1)\n",
    "X = X.drop('Address', 1)\n",
    "X = X.drop('Index', 1)\n",
    "#X = X.drop('CITY OWNED',1)\n",
    "X = X.drop('Active Shed', 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "    \n",
    "print (\"Neural Network\")\n",
    "clf = MLPClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Neural Network\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "print (\"Neural Network changing params...\")\n",
    "hidden_layer_list = [(10,10),(15,15,15),(40,45,50),(80,85),(35,15),(55),(80)]\n",
    "\n",
    "maximumIter = 500\n",
    "    \n",
    "#max_features = sqrt(number of features)\n",
    "\n",
    "for max_h in hidden_layer_list:\n",
    "    #print \"max features\", maximumFeat\n",
    "        clf = MLPClassifier(max_iter = maximumIter, hidden_layer_sizes = max_h, random_state = 0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        a = \"max iter:\" + str(maximumIter)\n",
    "        b = \"hidden layers:\" + str(max_h)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "        print(\"Going through params...\")\n",
    "    \n",
    "data_nn = pd.DataFrame(model_selection, columns=('Model','Parameters', 'Training Score', 'Test Score', 'Precision', 'Recall', 'F1', 'AUC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.939925</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.820777</td>\n",
       "      <td>0.937794</td>\n",
       "      <td>0.875392</td>\n",
       "      <td>0.933259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(10, 10))</td>\n",
       "      <td>0.873765</td>\n",
       "      <td>0.799196</td>\n",
       "      <td>0.764373</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>0.810614</td>\n",
       "      <td>0.876290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(15, 15, 15))</td>\n",
       "      <td>0.917760</td>\n",
       "      <td>0.834869</td>\n",
       "      <td>0.802495</td>\n",
       "      <td>0.886685</td>\n",
       "      <td>0.842492</td>\n",
       "      <td>0.894326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(40, 45, 50))</td>\n",
       "      <td>0.940260</td>\n",
       "      <td>0.854798</td>\n",
       "      <td>0.807951</td>\n",
       "      <td>0.929388</td>\n",
       "      <td>0.864425</td>\n",
       "      <td>0.916097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(80, 85))</td>\n",
       "      <td>0.939479</td>\n",
       "      <td>0.864177</td>\n",
       "      <td>0.821588</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.872021</td>\n",
       "      <td>0.927779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(35, 15))</td>\n",
       "      <td>0.935459</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.832873</td>\n",
       "      <td>0.911567</td>\n",
       "      <td>0.870445</td>\n",
       "      <td>0.920079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:55)</td>\n",
       "      <td>0.937580</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.825099</td>\n",
       "      <td>0.915266</td>\n",
       "      <td>0.867846</td>\n",
       "      <td>0.924751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:80)</td>\n",
       "      <td>0.939423</td>\n",
       "      <td>0.867359</td>\n",
       "      <td>0.820505</td>\n",
       "      <td>0.939139</td>\n",
       "      <td>0.875823</td>\n",
       "      <td>0.934170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model                                 Parameters  Training Score  \\\n",
       "0  Neural Network                          (default,default)        0.939925   \n",
       "1  Neural Network      (max iter:500,hidden layers:(10, 10))        0.873765   \n",
       "2  Neural Network  (max iter:500,hidden layers:(15, 15, 15))        0.917760   \n",
       "3  Neural Network  (max iter:500,hidden layers:(40, 45, 50))        0.940260   \n",
       "4  Neural Network      (max iter:500,hidden layers:(80, 85))        0.939479   \n",
       "5  Neural Network      (max iter:500,hidden layers:(35, 15))        0.935459   \n",
       "6  Neural Network            (max iter:500,hidden layers:55)        0.937580   \n",
       "7  Neural Network            (max iter:500,hidden layers:80)        0.939423   \n",
       "\n",
       "   Test Score  Precision    Recall        F1       AUC  \n",
       "0    0.867024   0.820777  0.937794  0.875392  0.933259  \n",
       "1    0.799196   0.764373  0.862811  0.810614  0.876290  \n",
       "2    0.834869   0.802495  0.886685  0.842492  0.894326  \n",
       "3    0.854798   0.807951  0.929388  0.864425  0.916097  \n",
       "4    0.864177   0.821588  0.929052  0.872021  0.927779  \n",
       "5    0.864847   0.832873  0.911567  0.870445  0.920079  \n",
       "6    0.861162   0.825099  0.915266  0.867846  0.924751  \n",
       "7    0.867359   0.820505  0.939139  0.875823  0.934170  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Overfitting in Neural Network by Using holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenf2 = int(len(f2) * 0.20)\n",
    "lenf2\n",
    "\n",
    "df = f2[0:lenf2] # 20 percent\n",
    "dfb = f2[lenf2:] # 80 percent\n",
    "\n",
    "dfb = dfb.drop(\"Bin\",1)\n",
    "dfb = dfb.drop(\"Address\",1)\n",
    "dfb = dfb.drop(\"Index\",1)\n",
    "dfb = dfb.drop(\"Active Shed\",1)\n",
    "\n",
    "df = df.drop(\"Bin\",1)\n",
    "df = df.drop(\"Address\",1)\n",
    "df = df.drop(\"Index\",1)\n",
    "df = df.drop(\"Active Shed\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network changing params...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\tahalam\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done.\n"
     ]
    }
   ],
   "source": [
    "# The 80% datasets comes from the modified datasets we had above. \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model_selection=[]\n",
    "    \n",
    "def AccuracyAndAUC(model, clf, X_test, y_test, a, b):\n",
    "    a = \"(\" + a + \",\"\n",
    "    b = b + \")\"\n",
    "    accuracy_param = a + b\n",
    "    clf_predicted = clf.predict(X_test)\n",
    "   \n",
    "        \n",
    "    pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    roc=roc_auc_score(y_test, pred_prob)\n",
    "    #print ('AUC:', round(roc, 2))\n",
    "\n",
    "        \n",
    "    #clf_predicted = clf.predict(X_test)\n",
    "    #confusion = confusion_matrix(y_test, clf_predicted)\n",
    "\n",
    "    #print('Classifier Confusion Matrix\\n', confusion)\n",
    "    #print()\n",
    "        \n",
    "    model_selection.append([model,accuracy_param, clf.score(X_train, y_train), accuracy_score(y_test, clf_predicted),\n",
    "                               precision_score(y_test, clf_predicted),recall_score(y_test, clf_predicted),\n",
    "                            f1_score(y_test, clf_predicted), roc])\n",
    "\n",
    "#model\n",
    "y = dfb[\"Outcome\"]\n",
    "X = dfb.drop('Outcome', 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state = 0)\n",
    "\n",
    "print (\"Neural Network\")\n",
    "clf = MLPClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "model = \"Neural Network\"\n",
    "a = \"default\"\n",
    "b = \"default\"\n",
    "AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "    \n",
    "print (\"Neural Network changing params...\")\n",
    "hidden_layer_list = [(30),(60),(90),(120),(150),(210),(270),(300),\n",
    "                    \n",
    "                    (30,30),(60,60),(90,90),(120,120),(150,150),(210,210),(270,270),(300,300),\n",
    "                    \n",
    "                    (30,30,30),(60,60,60),(90,90,90),(120,120,120),(150,150,150),(210,210,210),(270,270,270),(300,300,300)]\n",
    "\n",
    "maximumIter = 500\n",
    "    \n",
    "#max_features = sqrt(number of features)\n",
    "\n",
    "for max_h in hidden_layer_list:\n",
    "    #print \"max features\", maximumFeat\n",
    "        clf = MLPClassifier(max_iter = maximumIter, hidden_layer_sizes = max_h, random_state = 0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        a = \"max iter:\" + str(maximumIter)\n",
    "        b = \"hidden layers:\" + str(max_h)\n",
    "        AccuracyAndAUC(model, clf, X_test, y_test, a, b)\n",
    "        \n",
    "        \n",
    "print(\"All done.\")\n",
    "    \n",
    "data_nn = pd.DataFrame(model_selection, columns=('Model','Parameters', 'Training Score', 'Test Score', 'Precision', 'Recall', 'F1', 'AUC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(default,default)</td>\n",
       "      <td>0.941704</td>\n",
       "      <td>0.864992</td>\n",
       "      <td>0.835597</td>\n",
       "      <td>0.915341</td>\n",
       "      <td>0.873653</td>\n",
       "      <td>0.928289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:30)</td>\n",
       "      <td>0.934703</td>\n",
       "      <td>0.852695</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.925603</td>\n",
       "      <td>0.865020</td>\n",
       "      <td>0.911090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:60)</td>\n",
       "      <td>0.941115</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>0.826790</td>\n",
       "      <td>0.918420</td>\n",
       "      <td>0.870199</td>\n",
       "      <td>0.921264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:90)</td>\n",
       "      <td>0.940984</td>\n",
       "      <td>0.865254</td>\n",
       "      <td>0.843391</td>\n",
       "      <td>0.903540</td>\n",
       "      <td>0.872430</td>\n",
       "      <td>0.925369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:120)</td>\n",
       "      <td>0.941573</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.849545</td>\n",
       "      <td>0.909697</td>\n",
       "      <td>0.878593</td>\n",
       "      <td>0.930173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:150)</td>\n",
       "      <td>0.942162</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.833103</td>\n",
       "      <td>0.927142</td>\n",
       "      <td>0.877610</td>\n",
       "      <td>0.931862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:210)</td>\n",
       "      <td>0.940330</td>\n",
       "      <td>0.867870</td>\n",
       "      <td>0.845124</td>\n",
       "      <td>0.907132</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.930487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:270)</td>\n",
       "      <td>0.939021</td>\n",
       "      <td>0.871010</td>\n",
       "      <td>0.847660</td>\n",
       "      <td>0.910723</td>\n",
       "      <td>0.878061</td>\n",
       "      <td>0.932762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:300)</td>\n",
       "      <td>0.941573</td>\n",
       "      <td>0.872318</td>\n",
       "      <td>0.848687</td>\n",
       "      <td>0.912263</td>\n",
       "      <td>0.879327</td>\n",
       "      <td>0.932934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(30, 30))</td>\n",
       "      <td>0.937778</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.908158</td>\n",
       "      <td>0.864680</td>\n",
       "      <td>0.908310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(60, 60))</td>\n",
       "      <td>0.939479</td>\n",
       "      <td>0.855573</td>\n",
       "      <td>0.810031</td>\n",
       "      <td>0.936378</td>\n",
       "      <td>0.868634</td>\n",
       "      <td>0.917946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(90, 90))</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.861591</td>\n",
       "      <td>0.821850</td>\n",
       "      <td>0.930221</td>\n",
       "      <td>0.872684</td>\n",
       "      <td>0.923362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(120, 120))</td>\n",
       "      <td>0.943405</td>\n",
       "      <td>0.867609</td>\n",
       "      <td>0.828104</td>\n",
       "      <td>0.934325</td>\n",
       "      <td>0.878014</td>\n",
       "      <td>0.919802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(150, 150))</td>\n",
       "      <td>0.943143</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.835408</td>\n",
       "      <td>0.929708</td>\n",
       "      <td>0.880039</td>\n",
       "      <td>0.929160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(210, 210))</td>\n",
       "      <td>0.943536</td>\n",
       "      <td>0.863684</td>\n",
       "      <td>0.821622</td>\n",
       "      <td>0.935865</td>\n",
       "      <td>0.875030</td>\n",
       "      <td>0.926177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(270, 270))</td>\n",
       "      <td>0.939675</td>\n",
       "      <td>0.863161</td>\n",
       "      <td>0.824091</td>\n",
       "      <td>0.930221</td>\n",
       "      <td>0.873946</td>\n",
       "      <td>0.922073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(300, 300))</td>\n",
       "      <td>0.942554</td>\n",
       "      <td>0.873888</td>\n",
       "      <td>0.849119</td>\n",
       "      <td>0.915341</td>\n",
       "      <td>0.880988</td>\n",
       "      <td>0.932078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(30, 30, 30))</td>\n",
       "      <td>0.935881</td>\n",
       "      <td>0.850078</td>\n",
       "      <td>0.821796</td>\n",
       "      <td>0.901488</td>\n",
       "      <td>0.859799</td>\n",
       "      <td>0.905343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(60, 60, 60))</td>\n",
       "      <td>0.939545</td>\n",
       "      <td>0.854265</td>\n",
       "      <td>0.806069</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>0.868103</td>\n",
       "      <td>0.918267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(90, 90, 90))</td>\n",
       "      <td>0.939872</td>\n",
       "      <td>0.855311</td>\n",
       "      <td>0.808576</td>\n",
       "      <td>0.938430</td>\n",
       "      <td>0.868677</td>\n",
       "      <td>0.915731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(120, 120, 120))</td>\n",
       "      <td>0.941049</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.807675</td>\n",
       "      <td>0.939456</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>0.911638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(150, 150, 150))</td>\n",
       "      <td>0.942620</td>\n",
       "      <td>0.875458</td>\n",
       "      <td>0.850547</td>\n",
       "      <td>0.916880</td>\n",
       "      <td>0.882469</td>\n",
       "      <td>0.933613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(210, 210, 210))</td>\n",
       "      <td>0.942227</td>\n",
       "      <td>0.858451</td>\n",
       "      <td>0.815412</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.870605</td>\n",
       "      <td>0.920469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(270, 270, 270))</td>\n",
       "      <td>0.943143</td>\n",
       "      <td>0.864992</td>\n",
       "      <td>0.824943</td>\n",
       "      <td>0.933299</td>\n",
       "      <td>0.875782</td>\n",
       "      <td>0.922648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>(max iter:500,hidden layers:(300, 300, 300))</td>\n",
       "      <td>0.942620</td>\n",
       "      <td>0.870487</td>\n",
       "      <td>0.840037</td>\n",
       "      <td>0.921498</td>\n",
       "      <td>0.878884</td>\n",
       "      <td>0.928640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model                                    Parameters  \\\n",
       "0   Neural Network                             (default,default)   \n",
       "1   Neural Network               (max iter:500,hidden layers:30)   \n",
       "2   Neural Network               (max iter:500,hidden layers:60)   \n",
       "3   Neural Network               (max iter:500,hidden layers:90)   \n",
       "4   Neural Network              (max iter:500,hidden layers:120)   \n",
       "5   Neural Network              (max iter:500,hidden layers:150)   \n",
       "6   Neural Network              (max iter:500,hidden layers:210)   \n",
       "7   Neural Network              (max iter:500,hidden layers:270)   \n",
       "8   Neural Network              (max iter:500,hidden layers:300)   \n",
       "9   Neural Network         (max iter:500,hidden layers:(30, 30))   \n",
       "10  Neural Network         (max iter:500,hidden layers:(60, 60))   \n",
       "11  Neural Network         (max iter:500,hidden layers:(90, 90))   \n",
       "12  Neural Network       (max iter:500,hidden layers:(120, 120))   \n",
       "13  Neural Network       (max iter:500,hidden layers:(150, 150))   \n",
       "14  Neural Network       (max iter:500,hidden layers:(210, 210))   \n",
       "15  Neural Network       (max iter:500,hidden layers:(270, 270))   \n",
       "16  Neural Network       (max iter:500,hidden layers:(300, 300))   \n",
       "17  Neural Network     (max iter:500,hidden layers:(30, 30, 30))   \n",
       "18  Neural Network     (max iter:500,hidden layers:(60, 60, 60))   \n",
       "19  Neural Network     (max iter:500,hidden layers:(90, 90, 90))   \n",
       "20  Neural Network  (max iter:500,hidden layers:(120, 120, 120))   \n",
       "21  Neural Network  (max iter:500,hidden layers:(150, 150, 150))   \n",
       "22  Neural Network  (max iter:500,hidden layers:(210, 210, 210))   \n",
       "23  Neural Network  (max iter:500,hidden layers:(270, 270, 270))   \n",
       "24  Neural Network  (max iter:500,hidden layers:(300, 300, 300))   \n",
       "\n",
       "    Training Score  Test Score  Precision    Recall        F1       AUC  \n",
       "0         0.941704    0.864992   0.835597  0.915341  0.873653  0.928289  \n",
       "1         0.934703    0.852695   0.811881  0.925603  0.865020  0.911090  \n",
       "2         0.941115    0.860283   0.826790  0.918420  0.870199  0.921264  \n",
       "3         0.940984    0.865254   0.843391  0.903540  0.872430  0.925369  \n",
       "4         0.941573    0.871795   0.849545  0.909697  0.878593  0.930173  \n",
       "5         0.942162    0.868132   0.833103  0.927142  0.877610  0.931862  \n",
       "6         0.940330    0.867870   0.845124  0.907132  0.875031  0.930487  \n",
       "7         0.939021    0.871010   0.847660  0.910723  0.878061  0.932762  \n",
       "8         0.941573    0.872318   0.848687  0.912263  0.879327  0.932934  \n",
       "9         0.937778    0.855050   0.825175  0.908158  0.864680  0.908310  \n",
       "10        0.939479    0.855573   0.810031  0.936378  0.868634  0.917946  \n",
       "11        0.939348    0.861591   0.821850  0.930221  0.872684  0.923362  \n",
       "12        0.943405    0.867609   0.828104  0.934325  0.878014  0.919802  \n",
       "13        0.943143    0.870748   0.835408  0.929708  0.880039  0.929160  \n",
       "14        0.943536    0.863684   0.821622  0.935865  0.875030  0.926177  \n",
       "15        0.939675    0.863161   0.824091  0.930221  0.873946  0.922073  \n",
       "16        0.942554    0.873888   0.849119  0.915341  0.880988  0.932078  \n",
       "17        0.935881    0.850078   0.821796  0.901488  0.859799  0.905343  \n",
       "18        0.939545    0.854265   0.806069  0.940482  0.868103  0.918267  \n",
       "19        0.939872    0.855311   0.808576  0.938430  0.868677  0.915731  \n",
       "20        0.941049    0.855050   0.807675  0.939456  0.868596  0.911638  \n",
       "21        0.942620    0.875458   0.850547  0.916880  0.882469  0.933613  \n",
       "22        0.942227    0.858451   0.815412  0.933812  0.870605  0.920469  \n",
       "23        0.943143    0.864992   0.824943  0.933299  0.875782  0.922648  \n",
       "24        0.942620    0.870487   0.840037  0.921498  0.878884  0.928640  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest 20% is from new dataset. \n",
    "#create training and test dataset. training datastes from the last 80% dataset that we used\n",
    "\n",
    "test = df.copy()\n",
    "train = dfb.copy()\n",
    "\n",
    "\n",
    "y_test = test[\"Outcome\"]\n",
    "X_test = test.drop('Outcome',1)\n",
    "\n",
    "y_train = train[\"Outcome\"]\n",
    "X_train = train.drop('Outcome',1)\n",
    "\n",
    "\n",
    "\n",
    "#previous best\n",
    "#clf = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 6, random_state = 0)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50),max_iter=1000, random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "result  =  clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8628559463986599\n",
      "Train Score: 0.9402282005652675\n",
      "precision: 0.8161683277962348\n",
      "recall: 0.9336993243243243\n",
      "f1: 0.8709868032302541\n",
      "AUC: 0.9263273603753255\n",
      "accuracy: 0.8628559463986599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "print(\"Test Score:\",clf.score(X_test, y_test))\n",
    "print(\"Train Score:\",clf.score(X_train, y_train))\n",
    "print('precision:',metrics.precision_score(y_test,result))\n",
    "print('recall:',metrics.recall_score(y_test,result))\n",
    "print(\"f1:\",metrics.f1_score(y_test,result))\n",
    "y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC:\",auc)\n",
    "print('accuracy:',accuracy_score(y_test,result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
